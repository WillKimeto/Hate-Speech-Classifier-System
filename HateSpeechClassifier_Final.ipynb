{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_j7EOKKdAXZ9",
        "outputId": "73e379b0-ced6-4850-d36a-b02cced8fb76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hate_speech  offensive_language  neither  Class  \\\n",
              "0            0                   0        3      0   \n",
              "1            0                   0        3      0   \n",
              "2            0                   0        3      0   \n",
              "3            0                   0        3      0   \n",
              "4            0                   0        3      0   \n",
              "\n",
              "                                               Tweet  \n",
              "0  ['The political elite are in desperation. Ordi...  \n",
              "1  [\"Am just curious the only people who are call...  \n",
              "2  ['USERNAME_3 the area politicians are the one ...  \n",
              "3  ['War expected in Nakuru if something is not d...  \n",
              "4  ['USERNAME_4 tells kikuyus activists that they...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07055a81-b3a0-44b8-a2f7-99d52ded8303\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>Class</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>['The political elite are in desperation. Ordi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"Am just curious the only people who are call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>['USERNAME_3 the area politicians are the one ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>['War expected in Nakuru if something is not d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>['USERNAME_4 tells kikuyus activists that they...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07055a81-b3a0-44b8-a2f7-99d52ded8303')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07055a81-b3a0-44b8-a2f7-99d52ded8303 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07055a81-b3a0-44b8-a2f7-99d52ded8303');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74f0ae91-78f1-4e52-900c-f140de96d524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74f0ae91-78f1-4e52-900c-f140de96d524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74f0ae91-78f1-4e52-900c-f140de96d524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 48076,\n  \"fields\": [\n    {\n      \"column\": \"hate_speech\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offensive_language\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neither\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48076,\n        \"samples\": [\n          \"['USERNAME_417 on something about religion and not jokes']\",\n          \"['Kenya belongs to Kikuyus & Kalenjins all others are slaves only Kikuyus are allowed to rule- Uhuru Kenyatta.']\",\n          \"[\\\"This is one of my fav weddings even though it's straight. They are both photographers that photograph the Masai in Kenya.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        " import pandas as pd\n",
        "df = pd.read_csv('/content/HateSpeech_Kenya.csv')\n",
        "# Display the first few rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to import the necessary libraries inorder to be able to perfom our task\n",
        "\n",
        "So we begin by importing all that is needed\n"
      ],
      "metadata": {
        "id": "q4GJDD1OBVWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import pickle\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t28xRWkhBcGS",
        "outputId": "a034e721-7eef-4733-97e5-958519f1026f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then view and explore the dataset"
      ],
      "metadata": {
        "id": "tLGLGIRYBoZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df['Class'].value_counts())\n",
        "\n",
        "text_column = 'Tweet'\n",
        "label_column = 'Class'\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD0bY9z4ByGp",
        "outputId": "bdb325b4-2277-4614-e485-3f803e34f94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['hate_speech', 'offensive_language', 'neither', 'Class', 'Tweet'], dtype='object')\n",
            "   hate_speech  offensive_language  neither  Class  \\\n",
            "0            0                   0        3      0   \n",
            "1            0                   0        3      0   \n",
            "2            0                   0        3      0   \n",
            "3            0                   0        3      0   \n",
            "4            0                   0        3      0   \n",
            "\n",
            "                                               Tweet  \n",
            "0  ['The political elite are in desperation. Ordi...  \n",
            "1  [\"Am just curious the only people who are call...  \n",
            "2  ['USERNAME_3 the area politicians are the one ...  \n",
            "3  ['War expected in Nakuru if something is not d...  \n",
            "4  ['USERNAME_4 tells kikuyus activists that they...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48076 entries, 0 to 48075\n",
            "Data columns (total 5 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   hate_speech         48076 non-null  int64 \n",
            " 1   offensive_language  48076 non-null  int64 \n",
            " 2   neither             48076 non-null  int64 \n",
            " 3   Class               48076 non-null  int64 \n",
            " 4   Tweet               48076 non-null  object\n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 1.8+ MB\n",
            "None\n",
            "Class\n",
            "0    36352\n",
            "1     8543\n",
            "2     3181\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then begin text processsing"
      ],
      "metadata": {
        "id": "z6gH2IK0CpW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Removing any missing values\n",
        "df.dropna(subset=['Tweet'], inplace=True)\n",
        "\n",
        "\n",
        "contractions = {\n",
        "    \"can't\": \"cannot\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"n't\": \" not\",\n",
        "    \"'re\": \" are\",\n",
        "    \"'s\": \" is\",\n",
        "    \"'d\": \" would\",\n",
        "    \"'ll\": \" will\",\n",
        "    \"'t\": \" not\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'m\": \" am\"\n",
        "}\n",
        "\n",
        "def expand_contractions(text, contractions_dict=contractions):\n",
        "    for key, value in contractions_dict.items():\n",
        "        text = text.replace(key, value)\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()  # This is to remove any HTML tags\n",
        "    text = text.lower()  # Converts texts into lowercase\n",
        "    text = expand_contractions(text)\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Removes punctuation in the text\n",
        "    text = re.sub(\"\\d+\", \"\", text)  #Removes numbers\n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stopwords.words('english')]  # Removes all stopwords\n",
        "    text = \" \".join(text)  #\n",
        "    return text\n",
        "\n",
        "# Applying preprocessing\n",
        "df['cleaned_text'] = df['Tweet'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JO3thZUCuJL",
        "outputId": "e8704269-bb2d-405e-df50-5f8b7d3f7102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "<ipython-input-9-81f07d9520c8>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # This is to remove any HTML tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfomring tokenization,stemming, POS tagging and lematization."
      ],
      "metadata": {
        "id": "l2FJSB_yDk7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def stem_text(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(word) for word in text]\n",
        "\n",
        "def pos_tag_text(text):\n",
        "    return nltk.pos_tag(text)\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in text]\n",
        "\n",
        "\n",
        "df['tokens'] = df['cleaned_text'].apply(tokenize_text)\n",
        "df['stemmed_tokens'] = df['tokens'].apply(stem_text)\n",
        "df['pos_tags'] = df['tokens'].apply(pos_tag_text)\n",
        "df['lemmatized_tokens'] = df['tokens'].apply(lemmatize_text)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['encoded_label'] = le.fit_transform(df[label_column])\n"
      ],
      "metadata": {
        "id": "gJnrpWueD2Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df['cleaned_text']\n",
        "y = df['encoded_label']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "qTP1Jl50FvCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "pfjdcEf6F6gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we start building our linear regression model"
      ],
      "metadata": {
        "id": "xmZt4B3gGAL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#Initializing and training the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "#Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JT_xtZyGDde",
        "outputId": "1a6d5b4f-0476-4afb-fa87-da69214da041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7476081530782029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.97      0.86      7166\n",
            "           1       0.43      0.11      0.17      1806\n",
            "           2       0.37      0.11      0.16       644\n",
            "\n",
            "    accuracy                           0.75      9616\n",
            "   macro avg       0.52      0.39      0.40      9616\n",
            "weighted avg       0.68      0.75      0.68      9616\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('hate_speech_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
        "    pickle.dump(vectorizer, file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('hate_speech_model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
        "    loaded_vectorizer = pickle.load(file)\n",
        "\n",
        "#Making predictions using the loaded model and vectorizer\n",
        "sample_text = [\"This is a test tweet\"]\n",
        "sample_text_tfidf = loaded_vectorizer.transform(sample_text)\n",
        "predicted_class = loaded_model.predict(sample_text_tfidf)\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOnnzEhHGTKL",
        "outputId": "a8b4a27f-4036-4196-9c35-86e60a4e1b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After perfoming the required cleaning steps(Tokenization,removing punctuation etc) and making sure the logistic regression model is accruate we then view the classified tweets which were singled out from the rest of the other tweets."
      ],
      "metadata": {
        "id": "Irfu68HjGh06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test = pd.DataFrame({\n",
        "    text_column: df.loc[X_test.index, text_column],\n",
        "    'cleaned_text': X_test,\n",
        "    'predicted_class': y_pred\n",
        "})\n",
        "\n",
        "#To the classified tweets\n",
        "print(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMSRSrmQG0DM",
        "outputId": "97a34e2f-3860-45d5-9692-de1aaa16436f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Tweet  \\\n",
            "465    ['USERNAME_417 on something about religion and...   \n",
            "22169  ['Kenya belongs to Kikuyus & Kalenjins all oth...   \n",
            "20879  [\"This is one of my fav weddings even though i...   \n",
            "26268    ['who are those colourful white luos ....?!!!']   \n",
            "2875   ['Well well well chinese say #GenghisKhan is c...   \n",
            "...                                                  ...   \n",
            "47601  ['Those accusing Luos of Migori hooliganism.Wh...   \n",
            "30139  ['Bei ya unga na maziwa ziko uko juu us luhyas...   \n",
            "15381  ['When it comes to crossing the Moroccan deser...   \n",
            "7020   ['Luhya tweet~ RTp USERNAME_1514: am the type ...   \n",
            "38508  ['Kikuyus are in every corner of the republic ...   \n",
            "\n",
            "                                            cleaned_text  predicted_class  \n",
            "465                    username something religion jokes                0  \n",
            "22169  kenya belongs kikuyus kalenjins others slaves ...                2  \n",
            "20879  one fav weddings even though straight photogra...                0  \n",
            "26268                               colourful white luos                0  \n",
            "2875   well well well chinese say genghiskhan chinese...                0  \n",
            "...                                                  ...              ...  \n",
            "47601  nothose accusing luos migori hooliganismwhat s...                0  \n",
            "30139  bei ya unga na maziwa ziko uko juu us luhyas t...                0  \n",
            "15381  comes crossing moroccan desert username rider ...                0  \n",
            "7020   luhya tweet rtp username type guy cook nice ug...                0  \n",
            "38508  kikuyus every corner republic sorts many good ...                0  \n",
            "\n",
            "[9616 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ]
}